---
title: "Biostat 203B Homework 1"
author: Pablo Geraldo
date: \today
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Display machine information for reproducibility:
```{r, eval=T}
sessionInfo()
```

## Q1. Git/GitHub

**No handwritten homework reports are accepted for this course.** We work with Git and GitHub. Efficient and abundant use of Git, e.g., frequent and well-documented commits, is an important criterion for grading your homework.

1. Apply for the [Student Developer Pack](https://education.github.com/pack) at GitHub using your UCLA email.

Done!

2. Create a **private** repository `biostat-203b-2021-winter` and add `Hua-Zhou`, `Chris-German` and `ElvisCuiHan` as your collaborators with write permission.

Done!

3. Top directories of the repository should be `hw1`, `hw2`, ... Maintain two branches `master` and `develop`. The `develop` branch will be your main playground, the place where you develop solution (code) to homework problems and write up report. The `master` branch will be your presentation area. Submit your homework files (R markdown file `Rmd`, `html` file converted from R markdown, all code and data sets to reproduce results) in `master` branch.

Done!

4. After each homework due date, teaching assistant and instructor will check out your master branch for grading. Tag each of your homework submissions with tag names `hw1`, `hw2`, ... Tagging time will be used as your submission time. That means if you tag your `hw1` submission after deadline, penalty points will be deducted for late submission.

5. After this course, you can make this repository public and use it to demonstrate your skill sets on job market.

## Q2. Linux Shell Commands

1. This exercise (and later in this course) uses the [MIMIC-IV data](https://mimic-iv.mit.edu), a freely accessible critical care database developed by the MIT Lab for Computational Physiology. Follow the instructions at <https://mimic-iv.mit.edu/docs/access/> to (1) complete the CITI `Data or Specimens Only Research` course and (2) obtain the PhysioNet credential for using the MIMIC-IV data. Display the verification links to your completion report and completion certificate here. (Hint: The CITI training takes a couple hours and the PhysioNet credentialing takes a couple days; do not leave it to the last minute.)

Here are my credentials from having completed the training at CITI:

* [Completion Report](https://www.citiprogram.org/verify/?k4374b705-da14-4075-b055-51edd0043849-40321907)
* [Completion Certificate](https://www.citiprogram.org/verify/?w9dcaffff-1e96-413e-8719-f9feb00bc2b1-40321907)

2. The `/usr/203b-data/mimic-iv/` folder on teaching server contains data sets from MIMIC-IV. Refer to <https://mimic-iv.mit.edu/docs/datasets/> for details of data files.  
    ```{bash}
    ls -l /usr/203b-data/mimic-iv
    ```
Please, do **not** put these data files into Git; they are big. Do **not** copy them into your directory. Do **not** decompress the gz data files. These create unnecessary big files on storage and are not big data friendly practices. Just read from the data folder `/usr/203b-data/mimic-iv` directly in following exercises. 

    Use Bash commands to answer following questions.

3. Display the contents in the folders `core`, `hosp`, `icu`. What are the functionalities of the bash commands `zcat`, `zless`, `zmore`, and `zgrep`? 

First, the following code will display the content in the respective directories. I counted 3 files in the `core` directory, 17 files in the `hosp` directory, and 7 files in the `icu` directory.

```{bash}
# Display files in the core folder (3 files)
ls -l /usr/203b-data/mimic-iv/core
# Display files in the hosp folder (17 files)
ls -l /usr/203b-data/mimic-iv/hosp
# Display files in the icu folder (7 files)
ls -l /usr/203b-data/mimic-iv/icu
```

Now, let's explain the commands listed. The command `zcat` is to decompress and read a big file  (according to `help zcat` it is equivalent to `gunzip -c`, where the `-c` option means that the output is written on standard output). It is not recommended, since the screen gets overwhelmed with information.

The command `zless` allows to read sections of a compressed file without decompressing the entire file, so it is very convenient to explore big files (the output is paginated). The `zmore` command works very similarly, printing the output one screen at a time too. They are equivalent to `zcat file.gz | less` and `zcat file.gz | less` respectively. In both cases, the original file remains unchanged.

Finally, the `zgrep` command allows the user to search for a specific word or pattern (technically, any regular expression) inside the files. For example (see the code below), one can ask for the count (`-c` option) of the times a patient is either admitted to or discharged into an "EMERGENCY ROOM".


```{bash, eval=FALSE}
# Example of the commands used (not executed here)
zcat /usr/203b-data/mimic-iv/core/admissions.csv.gz
zless /usr/203b-data/mimic-iv/core/admissions.csv.gz
zmore /usr/203b-data/mimic-iv/core/admissions.csv.gz
zgrep -c "EMERGENCY ROOM" /usr/203b-data/mimic-iv/core/admissions.csv.gz
```

4. What's the output of following bash script?
```{bash, eval=TRUE}
for datafile in /usr/203b-data/mimic-iv/core/*.gz
  do
    ls -l $datafile
  done
```
    
As shown in the output, the code prints the list of files matching the specified extension (*.gz) that are located in the directory (in this case, `/usr/203b-data/mimic-iv/core/`).

Display the number of lines in each data file using a similar loop.

One way (for sure not the only way and probably not the better!) to count the number of lines in each data file using a similar loop is to first scan the file using `zcat` and then piping the output and count the lines (with the option `wc -l`). This is the approach I illustrate below:

First, let's do it for the `core` directory:

```{bash, eval=TRUE}
# For the files in the core folder
for datafile in /usr/203b-data/mimic-iv/core/*.gz
  do
    echo "The number of lines in $datafile is "
    zcat $datafile | wc -l
  done
```
Now, let's consider the `hosp` directory:

```{bash, eval=FALSE}
# For the files in the hosp folder (takes some time to run)
for datafile in /usr/203b-data/mimic-iv/hosp/*.gz
  do
    echo "The number of lines in $datafile is "
    zcat $datafile | wc -l
  done
```

Finally, for the `icu` folder:

```{bash, eval=TRUE}
# For the files in the icu folder
for datafile in /usr/203b-data/mimic-iv/icu/*.gz
  do
    echo "The number of lines in $datafile is "
    zcat $datafile | wc -l
  done
```

5. Display the first few lines of `admissions.csv.gz`. How many rows are in this data file? How many unique patients (identified by `subject_id`) are in this data file? What are the possible values taken by each of the variable `admission_type`, `admission_location`, `insurance`, `language`, `marital_status`, and `ethnicity`? Also report the count for each unique value of these variables. (Hint: combine Linux commands `zcat`, `head`/`tail`, `awk`, `uniq`, `wc`, and so on.)

Here, I display the first five lines of the `admissions.csv.gz` file:

```{bash}
# First, display the first 5 lines in the file
zcat /usr/203b-data/mimic-iv/core/admissions.csv.gz | head -n 5
```

Now, I count the number of rows in the data. I'm starting the count in line 2 to skip the header, so it will be the number of cases. The total number of rows including the header will be the same +1 (see **Q2.4** above): 

```{bash}
# Second, count the rows in the data file (following the example above)
# using tail +2 to skip the first line (header)
# 
echo "The number of rows in the data is "
zcat /usr/203b-data/mimic-iv/core/admissions.csv.gz | tail -n +2 | wc -l
```

Now, to identify unique patients, I use the code below:

```{bash}
# Third, count unique patients
# tail -n +2: to start counting in the second row (skipping header)
# awk -F, declares the "," as separator, 
# and keep only the first column (subject_id): '{print $1}'
# Then sort by id, select unique cases and count
# This register how many times a subject appears
# So then I counted lines (wc -l)

echo "The number of unique patients in the file is "
zcat /usr/203b-data/mimic-iv/core/admissions.csv.gz | tail -n +2 | awk -F, '{print $1}' | sort | uniq -c | wc -l
```

## Q3. Who's popular in Price and Prejudice

1. You and your friend just have finished reading *Pride and Prejudice* by Jane Austen. Among the four main characters in the book, Elizabeth, Jane, Lydia, and Darcy, your friend thinks that Darcy was the most mentioned. You, however, are certain it was Elizabeth. Obtain the full text of the novel from <http://www.gutenberg.org/cache/epub/42671/pg42671.txt> and save to your local folder. 

```{bash}
# Copy from url and export to .txt file
curl http://www.gutenberg.org/cache/epub/42671/pg42671.txt > pride_and_prejudice.txt
```

Do **not** put this text file `pride_and_prejudice.txt` in Git. Using a `for` loop, how would you tabulate the number of times each of the four characters is mentioned?

```{bash}
for value in Elizabeth Jane Lydia Darcy
  do
    echo "The number of times $value is named is"
    grep -c $value pride_and_prejudice.txt
  done
```


2. What's the difference between the following two commands?
    ```{bash eval=FALSE}
    echo 'hello, world' > test1.txt
    ```
    and
    ```{bash eval=FALSE}
    echo 'hello, world' >> test2.txt
    ```

The first command, with only one assignment, will redirect the output from the screen to a file named `test1.txt`. If a file with that name does not exist, it will be created; if it exist, it will be overwritten. The second command, on the other hand, will create the file if it does not exist, but if exist it will append the new lines at the end instead of replacing the file.

3. Using your favorite text editor (e.g., `vi`), type the following and save the file as `middle.sh`:

```{bash eval=FALSE}
#!/bin/sh
# Select lines from the middle of a file.
# Usage: bash middle.sh filename end_line num_lines
head -n "$2" "$1" | tail -n "$3"
```

Using `chmod` make the file executable by the owner, 

```{bash, eval=FALSE}
# Make the file executable (+x)  by the owner (u)
chmod u+x middle.sh
```

and run 

```{bash}
./middle.sh pride_and_prejudice.txt 20 5
```

Explain the output. Explain the meaning of `"$1"`, `"$2"`, and `"$3"` in this shell script. Why do we need the first line of the shell script?

The author is showing the author and editor of the book, which we selected from the original `.txt` file by position: first, keeping only the first 20 lines, lines selecting the last 5 lines of the result. That is exactly the place where author and editor appears. We can change the parameters and we would move to somewhere else in the document.

In the code, we have to declare the file we are analyzing (`pride_and_prejudice.txt`), the number of lines we want to keep from the beginning of the document (here, 20 lines), and them how many we want to keep from bottom up (in this case, 5 lines). So, the code is equivalent to running this line: 

```{bash, eval=FALSE}
head -n 20 pride_and_prejudice.txt | tail -n 5
```

But, since the `middle.sh` file is a program, it has placeholders for its general arguments. The `$number` indicates a position. So, basically when calling the program we enter the arguments as file, head position, tail position, but they map into the source script in the correct order. For example, our first argument `filename` goes into the second position of the original file, and so on.

The first line is called a `shebang`, or the combination of hashtag and exclamation mark, that is instructing which kernel should be used to execute the file (in this case, the `sh` shell). The rest of the document is understood as `sh` code.

### Q4. More fun with Linux

Try these commands in Bash and interpret the results: `cal`, `cal 2021`, `cal 9 1752` (anything unusual?), `date`, `hostname`, `arch`, `uname -a`, `uptime`, `who am i`, `who`, `w`, `id`, `last | head`, `echo {con,pre}{sent,fer}{s,ed}`, `time sleep 5`, `history | tail`.

The commands `cal` prints the current month, while `cal year` will print the entire calendar for the indicated year.

```{bash, eval = FALSE}
cal # Outputs the calendar of the current year/month
cal 2021 # Outputs the calendar of the entire year
```

A special situation happens with `cal 9 1752`, which prints a month skipping from the day 2 directly to 14. According to [Wikipedia](https://en.wikipedia.org/wiki/Cal_(Unix)), this is due to the adoption of the Gregorian calendar (from the previous Julian) that month and year in Britain.

```{bash}
cal 9 1752
```
The command `date` prints the current day, date and time in the UTC time zone.

```{bash}
date
```

The command `hostname` prints the name of the server one is working on, in this case, the server for this class.

```{bash}
hostname
```

The command `arch` prints the computer architecture of the server. In this particular case, is a `x86_64` machine. I tried finding some more information about this and I understood that it has to do with the specific hardware used and its storing/computation capabilities. More in [Wikipedia](https://en.wikipedia.org/wiki/X86-64)

```{bash}
arch
# uname -m would return the same
```

The command `uname` prints the information about the system, the `-a` option is to print it all (including operating system, the network information, kernel information and release, processor). More information [here](https://www.computerhope.com/unix/uuname.htm)

```{bash}
uname -a
```

The `uptime` command display the time that the server has been working, the current time, number of users currently logged in, and the average CPU use over the last 1, 5, and 15 minutes.

```{bash}
uptime
```

The `whoami` command displays the username of the logged user (in other words, mine)

```{bash}
whoami
```

The `who` command list all the users that are currently logged in.

```{bash}
who
```
Similarly, `w` command list all the active users but with more details, indicating where are the connected from and what they are doing.

```{bash}
w
```
The `id` command prints the (current) user, their group id and memberships, and the security credentials.

```{bash}
id
# Can also specify id username
```

The command `last` lists the last users logged into the server, and when pipped to `head` it will list only the last ten (included currently logged users)

```{bash}
last | head
```
The command `echo` prints what the user enters. In this case, it subsequently concatenates what is in the first bracket with the second and the third, creating all combinations.

```{bash}
echo {con,pre}{sent,fer}{s,ed}
```

The command `time sleep 5` is telling the system to "freeze" for 5 seconds, and returning the elapsed time. Finally, pipping `history | tail` will print the history of last commands one has ran, keeping the last 10 (by `tail`). In this case, it is only keeping record of this particular chunck, so the record is pretty short.

```{bash}
# First, activate the history record
set -o history 
time sleep 5
history | tail
```

