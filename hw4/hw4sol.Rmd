---
title: "Biostat 203B Homework 4"
author: Pablo Geraldo
subtitle: Due Mar 12 @ 11:59PM
output:
  # ioslides_presentation: default
  html_document:
    toc: true
    toc_depth: 4
---

```{r, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```
                      
Display machine information:
```{r}
sessionInfo()
```
Load database libraries and the tidyverse frontend:
```{r}
library(tidyverse)
library(lubridate)
library(miceRanger)
```

## Q1. Missing data

Through the Shiny app developed in HW3, we observe abundant missing values in the MIMIC-IV ICU cohort we created. In this question, we use multiple imputation to obtain a data set without missing values.

0. Read following tutorials on the R package miceRanger for imputation: <https://github.com/farrellday/miceRanger>, <https://cran.r-project.org/web/packages/miceRanger/vignettes/miceAlgorithm.html>.

    A more thorough book treatment of the practical imputation strategies is the book [*_Flexible Imputation of Missing Data_*](https://stefvanbuuren.name/fimd/) by Stef van Buuren. 

1. Explain the jargon MCAR, MAR, and MNAR.

In missing data analysis, it is common to refer to this typology, explained in detail by [Little and Rubin (1987)](https://www.google.com/books/edition/Statistical_Analysis_with_Missing_Data/OaiODwAAQBAJ?hl=en&gbpv=0) "Statistical Analysis with Missing Data". The key point is to identify the reasons why some data is not observed in our dataset and, depending on the process generating missingness, the appropriate way to handle it could change.

**MCAR** (Missing Completely at Random) refers to the case where some values on a variable of interest are unrecorded, but there is no systematic association between that missingness and the observed variables, nor any parameter of interest. This is the same to saying that the complete cases are a random sample of the population of interest, so a complete case analysis would be unbiased.

**MAR** (Missing at Random) refers to the case where we have missing values in a variable of interest, and that missingness *is associated* with the underlying, unobserved values. This means that a complete case analysis would be biased. However, if the process generating missingness is **MAR**, this means that it is *conditionally* at random. In other words, conditional on covariates, what we observed is a random sample of the underlying values. In this case is when multiple imputation, and other imputation methods, actually works, since they impute the missing values based on the values of other, observed, covariates.

**MNAR** (Missing Not at Random), finally, refers to the case where the missingness pattern in a variable of interest is associated to its underlying (unobserved) values, in a way that is not dependent or captures by observed covariates. In this case, there is no way to recover or approximate the values that the variable would have attained have it been completely observed, and therefore no imputation method would do a good job in approximating the full data. Although imputation methods, including multiple imputation, might ameliorate the bias in the complete case analysis, no method would be enough to completely remove bias.

From this brief explanation, we can obtain a few take-aways. First, not all missing data is created equal. Depending on the missingness mechanism, multiple imputation might, or might not, help. Second, that the *missingness mechanism* refers to each variable at a time, not the complete dataset. In other words, we can have in the same dataset variables that are **MCAR** so don't need imputation, others that are **MAR** so we can successfully impute them using a MI algorithm, and variables that are **MNAR**, and therefore no imputation would recover the true distribution. 

Finally, beyond the scope of this explanation but important to mention, is the development of some recent graph-based versions of these categories, that allow researchers to justify their reasoning about missingness using their substantive understanding represented in graphical model. This approach has provided conditioning under which we can address even in the **MNAR** case. More details can be found in [Mohan and Pearl (2021)](https://ftp.cs.ucla.edu/pub/stat_ser/r473-L.pdf).



2. Explain in a couple of sentences how the Multiple Imputation by Chained Equations (MICE) work.

The MICE algorithm works by iterating over a series of predictive models built for each variable at a time, going over all variables to impute, and finish when the algorithm converges:

* Select a variable to impute: `data$v`
* Randomly complete missing entries for all other variables: `data[,-v]`
* Use the `-v` variables as features in the prediction model for `v`
* Iterate across variables until all have been imputed
* Repeat, starting from the imputed dataset, until convergence.

Here, convergence refer to approximating the correlation between variables in the original data. How fast the algorithm converges would depend on how informative the data is; the higher the original correlation, the faster.

Alternatively, instead of the predictive model approach just described, a "predictive mean matching" method can be used. This is just an application of knn to impute missing values, that is most useful to impute multimodal, integer or skewed variables, cases where the predictive approach tend to fail.


3. Perform a data quality check of the ICU stays data. Discard variables with substantial missingness, say >5000 `NA`s. Replace apparent data entry errors by `NA`s.

First, let's start by exploring our dataset. Here I print the data before any missing data imputation for reference.

```{r, cache=TRUE}
# Load the dataset
path <- "/home/pdgeraldo/biostat-203b-2021-winter/hw3/mimiciv_shiny"
data <- readRDS(paste0(path,"/icu_cohort.rds"))
print(data, width = Inf)
```

We have `r nrow(data)` observations and `r ncol(data)` variables. However, among these variables there are some which are uninformative for the imputation and modeling process, so I will remove them before proceeding. For example, I remove the three identifiers, but additionally `anchor_year_group` and `dod`. Also, it is important to note that the appropriate way of summarizing variables (and, later, of modeling their missingness) would vary for numeric versus categorical variables, so I would explore them separately.

Let's start with the categorical variables, exploring their distribution by the outcome of interest.

```{r, cache=TRUE}
# Use for some descriptive tables
library("SmartEDA")

# List categorical variables
catvars <- c("first_careunit",
             "last_careunit",
             "admission_type",
             "admission_location",
             "discharge_location",
             "insurance",
             "language",
             "marital_status",
             "ethnicity",
             "gender")

# Create table for categorical variables
data %>%
  select(all_of(catvars),
         mort30) %>%
  ExpCTable(Target = "mort30",
            margin=1, clim=10, nlim=3,
            round=2, bin=NULL, per=FALSE)
```

From exploring the categorical variables in our dataset, we can observe a few patterns. First, there are many variables without missing values, or with unspecific but still informative values. For example, the `language` variable contains "English" and "?" as possibles answers, but we can easily transform this into a binary variable `speaks_english` yes or no. In the case of `marital_status`, we have `r nrow(data[data$marital_status=="NA",])` missing values, so this is a candidate for imputation (valid values are Divorced, Married, Single and Widowed). Finally, we have the `ethnicity` variable, with `r nrow(data[data$ethnicity=="UNKNOWN",])` declared as "unknown", and `r nrow(data[data$ethnicity=="UNABLE TO OBTAIN",])` declared as "unable to obtain. Valid answers are American Indian/Alaska Native, Asian, Black/African American, Hispanic/Latino, White, and Other. For the sake of this exercise, I will also consider this as a candidate for imputation, although 

```{r, cache=TRUE}
# List numerical variables
numvars <- data %>%
  # Remove identifiers and other useless vars
  select(-subject_id, -hadm_id,
         -stay_id, -dod, -deathdiff,
         -anchor_year_group,
         # Remove categorical vars
         -all_of(catvars)) %>%
  names()

# Summarize numerical variables
data %>% 
  select(all_of(numvars)) %>%
  ExpNumStat(by = "G", gp = "mort30",
             Qnt = seq(0,1,0.25),
             MesofShape = 1,
             Outlier = TRUE,
             round = 2)
```

4. Impute missing values by `miceRanger` (request $m=3$ datasets). This step is very computational intensive. Make sure to save the imputation results as a file.

5. Make imputation diagnostic plots and explain what they mean.

6. Obtain a complete data set by averaging the 3 imputed data sets.

## Q2. Predicting 30-day mortality

Develop at least two analytic approaches for predicting the 30-day mortality of patients admitted to ICU using demographic information (gender, age, marital status, ethnicity), first lab measurements during ICU stay, and first vital measurements during ICU stay. For example, you can use (1) logistic regression (`glm()` function), (2) logistic regression with lasso penalty (glmnet package), (3) random forest (randomForest package), or (4) neural network.

1. Partition data into 80% training set and 20% test set. Stratify partitioning according the 30-day mortality status.

2. Train the models using the training set.

3. Compare model prediction performance on the test set.

